{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "path_base = \"C:\\\\Users\\\\16462\\\\OneDrive\\\\Desktop\\\\assignments\\\\PA\\\\Billboard\\\\billboard\\\\\"\n",
    "\n",
    "data_map = {}\n",
    "\n",
    "start_year=2008\n",
    "end_year=2014\n",
    "# Get Data as [Year, DF] combo\n",
    "for i in range (start_year, end_year):\n",
    "    filename = path_base+str(i)+\".csv\"\n",
    "    with open(filename) as file:\n",
    "        lines = [line.encode('utf-8', errors='ignore').decode('utf-8') for line in file]\n",
    "        df = pd.read_csv(StringIO('\\n'.join(lines)), header=0)\n",
    "        data_map[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relevant data from Spotify API for the same\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "client_id = '16a3911229cf4fc99361a96d524e6a99'\n",
    "client_secret = '6038b52110c24d3fac28a5ef1178ad47'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)\n",
    "\n",
    "def generate_artists(artist_list):\n",
    "    # Generate all possible artists with break points\n",
    "    # feat. / comma / and / with\n",
    "    return [x.strip() for x in re.split('feat.|and|with|,', artist_list)]\n",
    "\n",
    "def handle_special_cases(artist, track):\n",
    "    # Try and remove and search by each artist sequentially\n",
    "    artist_list = generate_artists(artist_list=artist)\n",
    "    for curr_artist in artist_list:\n",
    "        track_id = sp.search(q='artist: '+ curr_artist +' track:' + track, type='track')\n",
    "        base_data = track_id['tracks']['items']\n",
    "        if(base_data):\n",
    "                return base_data[0]['id']\n",
    "    # Try without artist data as last straw\n",
    "    track_id = sp.search(q=' track:' + track, type='track')\n",
    "    base_data =  track_id['tracks']['items']\n",
    "    if(not base_data):\n",
    "        return 0\n",
    "    return base_data[0]['id']\n",
    "\n",
    "def generate_track_ids(df):\n",
    "    final_lst = []\n",
    "    for ind in df.index:\n",
    "        artist = df['Artist'][ind]\n",
    "        track =  df['Song Title'][ind]\n",
    "        track_id = sp.search(q='artist: '+ artist +' track:' + track, type='track')\n",
    "        base_data = track_id['tracks']['items']\n",
    "        if(not base_data):\n",
    "            final_lst.append(handle_special_cases(artist=artist, track=track))\n",
    "            continue\n",
    "        final_lst.append(base_data[0]['id'])\n",
    "    return final_lst\n",
    "\n",
    "\n",
    "def generate_components_from_track_ids(df):\n",
    "    track_id_lst = df['spotify_track_ids']\n",
    "    df_features = pd.DataFrame(columns= ['danceability', 'energy', 'speechiness', 'acousticness', 'liveness', 'instrumentalness', 'valence', 'tempo', 'loudness'])\n",
    "    for id in track_id_lst:\n",
    "        if(id == 0):\n",
    "            dict_data = {'danceability' : 0, 'energy': 0,'speechiness': 0,'acousticness': 0, 'liveness': 0, 'instrumentalness': 0, 'valence': 0, 'tempo': 0, 'loudness': 0}\n",
    "        else:\n",
    "            base_features = sp.audio_features(id)[0]\n",
    "            dict_data = {'danceability' : base_features['danceability'], 'energy': base_features['energy'],'speechiness': base_features['speechiness'],'acousticness': base_features['acousticness'], 'liveness': base_features['liveness'], 'instrumentalness': base_features['instrumentalness'], 'valence': base_features['valence'], 'tempo': base_features['tempo'], 'loudness': base_features['loudness']}\n",
    "        df_features = pd.concat([df_features, pd.DataFrame.from_records([dict_data])])\n",
    "    return df_features\n",
    "\n",
    "\n",
    "\n",
    "def get_features_per_year(data_map):\n",
    "    for i in range(start_year, end_year):\n",
    "        base_df = data_map[i]\n",
    "        base_df['spotify_track_ids'] = generate_track_ids(base_df)\n",
    "        df_features = generate_components_from_track_ids(base_df)\n",
    "        base_df['danceability'] = list(df_features['danceability'])\n",
    "        base_df['energy'] = list(df_features['energy'])\n",
    "        base_df['speechiness'] = list(df_features['speechiness'])\n",
    "        base_df['acousticness'] = list(df_features['acousticness'])\n",
    "        base_df['liveness'] = list(df_features['liveness'])\n",
    "        base_df['instrumentalness'] = list(df_features['instrumentalness'])\n",
    "        base_df['valence'] = list(df_features['valence'])\n",
    "        base_df['tempo'] = list(df_features['tempo'])\n",
    "        base_df['loudness'] = list(df_features['loudness'])\n",
    "        data_map[i] = base_df\n",
    "\n",
    "get_features_per_year(data_map=data_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyricsgenius import Genius\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "lg_client_id = 'CQgAJwGPL9UggJTvrPNrHs-5Z7MsW_8NLB6Qf5wmMsdguul4G3wuXCwrMjPrFIbI'\n",
    "lg_client_secret = '89fcCi1qp8s8ym1foi--p7-uGVOeO-1vKVQFWZAcB-SJNbTPqCNviWljpbvQmwqj6YOjIqKumjgIEVM4q6q5eA'\n",
    "lg_access_token = 'hP5VBM1qM88JEGJwfl_NFD8Wv1bNo3nJZ5_zkis0McT2l4_wqqsfqKaNZLl-Kwa-'\n",
    "\n",
    "genius = Genius(access_token=lg_access_token, excluded_terms=[\"(Remix)\", \"(Live)\"], remove_section_headers=True, verbose=False)\n",
    "genius.timeout = 1\n",
    "genius.sleep_time = 1\n",
    "\n",
    "def print_data_to_csv(data_map, year):\n",
    "        df = data_map[year]\n",
    "        filename = \"test_\"+str(year)+\".csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "def gen_lyics_for_songs(data_map):\n",
    "    for i in range(start_year, end_year):\n",
    "        song_lyrics_lst= list()\n",
    "        df = data_map[i]\n",
    "        for ind in df.index:\n",
    "            artist = df['Artist'][ind]\n",
    "            track_name = df['Song Title'][ind]\n",
    "            retries = 0\n",
    "            found_song = False\n",
    "            while retries < 5 and found_song == False:\n",
    "                try:\n",
    "                    # Try and remove and search by each artist sequentially\n",
    "                    artist_list = generate_artists(artist_list=artist)\n",
    "                    for curr_artist in artist_list:\n",
    "                        song = genius.search_song(track_name, artist=curr_artist)\n",
    "                        if(song):\n",
    "                            song_lyrics_lst.append(song.lyrics)\n",
    "                            found_song = True\n",
    "                        if(found_song == True):\n",
    "                            break\n",
    "                    if(found_song == True):\n",
    "                        continue            \n",
    "                    # Search song without artist, take the topmost\n",
    "                    song = genius.search_song(track_name)\n",
    "                    if(song):\n",
    "                        song_lyrics_lst.append(song.lyrics)\n",
    "                        found_song = True\n",
    "                except Timeout as e:\n",
    "                    retries+=1\n",
    "                    continue\n",
    "                retries+=1\n",
    "            if(not song or found_song == False):\n",
    "                song_lyrics_lst.append(\"\")\n",
    "                continue\n",
    "        df['lyrics'] = song_lyrics_lst\n",
    "        data_map[i] = df\n",
    "        print_data_to_csv(data_map=data_map, year=i)\n",
    "\n",
    "\n",
    "\n",
    "gen_lyics_for_songs(data_map=data_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "import json\n",
    "import numpy as np\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features,CategoriesOptions,EmotionOptions,KeywordsOptions, ClassificationsOptions\n",
    "\n",
    "authenticator = IAMAuthenticator('21B4ablXnI9YFEOcJOsNrF79HgNz2pR74-Q8vDBvyM8q')\n",
    "tone_analyzer = NaturalLanguageUnderstandingV1(\n",
    "    version='2022-04-07',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "tone_analyzer.set_service_url('https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/95ef2705-e234-45fa-8592-9d4f05544c00')\n",
    "tone_analyzer.set_disable_ssl_verification(True)\n",
    "\n",
    "\n",
    "def store_sentiment_dataframe(df, year):\n",
    "        filename = \"sentiment_\"+str(year)+\".csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "def get_emotion(text, track_name):\n",
    "    if(text==\"\"):\n",
    "        print(track_name,\" No data of lyrics\")\n",
    "        return {\"anger\": 0.0, \"disgust\": 0.0, \"fear\": 0.0, \"joy\": 0.0, \"sadness\": 0.0}\n",
    "    json_output = tone_analyzer.analyze(text=text, features=Features(emotion=EmotionOptions(document=True)), language='en')\n",
    "    if(json_output.get_status_code() == 400 or json_output.get_status_code() == 500):\n",
    "        print(track_name,\"Invalid language\")\n",
    "        return {\"anger\": 0.0, \"disgust\": 0.0, \"fear\": 0.0, \"joy\": 0.0, \"sadness\": 0.0}\n",
    "    output = json_output.get_result()\n",
    "    emotion_data = output['emotion']['document']['emotion']\n",
    "    tones_dict = {\"anger\": emotion_data['anger'], \"disgust\": emotion_data['disgust'], \"fear\": emotion_data['fear'], \"joy\": emotion_data['joy'], \"sadness\": emotion_data['sadness']}\n",
    "    return tones_dict\n",
    "\n",
    "\n",
    "# Set songs for tone\n",
    "def get_emotion_for_each_song(data_map, st_year, ed_year):\n",
    "    for i in range(st_year, ed_year):\n",
    "        df = data_map[i]\n",
    "        df_features = pd.DataFrame(columns= ['anger', 'disgust', 'fear', 'joy', 'sadness'])\n",
    "        for ind in df.index:\n",
    "            lyrics = df[\"lyrics\"][ind]\n",
    "            df_lyric  = get_emotion(lyrics, df['Song Title'][ind])\n",
    "            df_features = pd.concat([df_features, pd.DataFrame.from_records([df_lyric])])\n",
    "        df['anger'] =  list(df_features['anger'])\n",
    "        df['disgust'] =  list(df_features['disgust'])\n",
    "        df['fear'] =  list(df_features['fear'])\n",
    "        df['joy'] =  list(df_features['joy'])\n",
    "        df['sadness'] =  list(df_features['sadness'])\n",
    "        data_map[i] = df\n",
    "        store_sentiment_dataframe(data_map[i],i)\n",
    "            \n",
    "        \n",
    "get_emotion_for_each_song(data_map=data_map, st_year=start_year+1, ed_year=end_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from files\n",
    "path_base = \"C:\\\\Users\\\\16462\\\\OneDrive\\\\Desktop\\\\assignments\\\\PA\\\\Billboard\\\\\"\n",
    "\n",
    "def get_data_into_dataframe():\n",
    "    for i in range(start_year, end_year):\n",
    "        filename = path_base+\"sentiment_\"+str(i)+\".csv\"\n",
    "        with open(filename,errors=\"replace\") as file:\n",
    "            df = pd.read_csv(file, header=0)\n",
    "            data_map[i] = df\n",
    "\n",
    "\n",
    "def calc_new_row(row):\n",
    "    if row['Position']<50:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def combine_dataframes_and_add_mega_hit():\n",
    "    combined_df = data_map[start_year]\n",
    "    for i in range(start_year+1, end_year):\n",
    "        combined_df = pd.concat([combined_df, data_map[i]])\n",
    "    combined_df = combined_df[combined_df['lyrics']!=\"\"]\n",
    "    combined_df['megahit'] = combined_df.apply(calc_new_row,axis=1)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "get_data_into_dataframe()\n",
    "combined_df = combine_dataframes_and_add_mega_hit()\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Linear SVC with Cross Validation\n",
      "Accuracy Score 0.6333333333333333\n",
      "R2 Score -0.5789473684210524\n",
      "Mean Squared Error 0.36666666666666664\n",
      "Root Mean Squared Error 0.6055300708194983\n",
      "\n",
      "For RBF SVC with Cross Validation\n",
      "Accuracy Score 0.5833333333333334\n",
      "R2 Score -0.7942583732057413\n",
      "Mean Squared Error 0.4166666666666667\n",
      "Root Mean Squared Error 0.6454972243679028\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = combined_df[['danceability', 'energy', 'speechiness', 'acousticness', 'liveness', 'instrumentalness', 'valence', 'tempo', 'loudness', 'anger', 'disgust', 'fear', 'joy', 'sadness']]\n",
    "Y = combined_df['megahit']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state=100)\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"For Linear SVC with Cross Validation\")\n",
    "print('Accuracy Score', accuracy_score(Y_test, predictions))\n",
    "print('R2 Score', r2_score(Y_test, predictions))\n",
    "print('Mean Squared Error',mean_squared_error(Y_test,predictions))\n",
    "print('Root Mean Squared Error', np.sqrt(mean_squared_error(Y_test,predictions)))\n",
    "print()\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma=0.01, C=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"For RBF SVC with Cross Validation\")\n",
    "print('Accuracy Score', accuracy_score(Y_test, predictions))\n",
    "print('R2 Score', r2_score(Y_test, predictions))\n",
    "print('Mean Squared Error',mean_squared_error(Y_test,predictions))\n",
    "print('Root Mean Squared Error', np.sqrt(mean_squared_error(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Multiple Regression with Cross Validation\n",
      "R2 Score 0.057844732053818904\n",
      "Mean Squared Error 0.21878939000083542\n",
      "Root Mean Squared Error 0.4677492811334245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "predictions = LR.predict(X_test)\n",
    "print(\"For Multiple Regression with Cross Validation\")\n",
    "print('R2 Score', r2_score(Y_test, predictions))\n",
    "print('Mean Squared Error', mean_squared_error(Y_test,predictions))\n",
    "print('Root Mean Squared Error', np.sqrt(mean_squared_error(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Decision Tree with  Entropy Classification,  Max Depth of 3 and Cross Validation\n",
      "Accuracy Score 0.7\n",
      "R2 Score -0.29186602870813383\n",
      "Mean Squared Error 0.3\n",
      "Root Mean Squared Error 0.5477225575051661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "clf = clf.fit(X_train,Y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"For Decision Tree with  Entropy Classification,  Max Depth of 3 and Cross Validation\")\n",
    "print('Accuracy Score', accuracy_score(Y_test, predictions))\n",
    "print('R2 Score', r2_score(Y_test, predictions))\n",
    "print('Mean Squared Error',mean_squared_error(Y_test,predictions))\n",
    "print('Root Mean Squared Error', np.sqrt(mean_squared_error(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest with Max Depth of 3 and Cross Validation\n",
      "Accuracy Score 0.6333333333333333\n",
      "R2 Score -0.5789473684210524\n",
      "Mean Squared Error 0.36666666666666664\n",
      "Root Mean Squared Error 0.6055300708194983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=3)\n",
    "clf.fit(X_train,Y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"For Random Forest with Max Depth of 3 and Cross Validation\")\n",
    "print('Accuracy Score', accuracy_score(Y_test, predictions))\n",
    "print('R2 Score', r2_score(Y_test, predictions))\n",
    "print('Mean Squared Error',mean_squared_error(Y_test,predictions))\n",
    "print('Root Mean Squared Error', np.sqrt(mean_squared_error(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f71d48bcfc261542abed45fd2aeec3595cfdb764230788a038a5aed20993e393"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
